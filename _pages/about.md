---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I’m a 2nd-year Ph.D. student in [Conversational AI Group](http://coai.cs.tsinghua.edu.cn/), Department of Computer Science and Technology, Tsinghua University. I’m advised by Prof. [Minlie Huang](http://coai.cs.tsinghua.edu.cn/hml). My research interests include Pre-trained Models for Natural Language Processing and Dialogue Systems.

Education
======

+ 2021.9 - Present: Ph.D. Student, Department of Computer Science and Technology, Tsinghua University
+ 2017.9 - 2021.6: B.Eng., Department of Computer Science and Technology, Tsinghua University

Publications
======

**Conference Papers**

+ **Yuxian Gu**, Pei Ke, Xiaoyan Zhu, Minlie Huang. Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization. **EMNLP 2022** (CCF-B, Long Paper, **Oral**). [[pdf]](https://arxiv.org/pdf/2210.09175.pdf) [[code]](https://github.com/thu-coai/UDIT)

+ **Yuxian Gu\***, Xu Han\*, Zhiyuan Liu, Minlie Huang. PPT: Pre-Trained Prompt Tuning for Few-Shot Learning. **ACL 2022** (CCF-A, Long Paper). [[pdf]](https://aclanthology.org/2022.acl-long.576.pdf) [[code]](https://github.com/thu-coai/PPT)

+ Qi Zhu, **Yuxian Gu**, Lingxiao Luo, Bing Li, Cheng Li, Wei Peng, Minlie Huang, Xiaoyan Zhu. When does Further Pre-Training MLM Help? An Empirical Study on Task-Oriented Dialog Pre-Training. **EMNLP 2021 Workshop** (***Best Paper***). [[pdf]](https://aclanthology.org/2021.insights-1.9.pdf) [[code]](https://github.com/zqwerty/ToDDAPT)

+ **Yuxian Gu**, Zhengyan Zhang, Xiaozhi Wang, Zhiyuan Liu, Maosong Sun. Train No Evil: Selective Masking for Task-Guided Pre-Training. **EMNLP 2020** (CCF-B, Short Paper). [[pdf]](https://aclanthology.org/2020.emnlp-main.566.pdf) [[code]](https://github.com/thunlp/SelectiveMasking)

+ Xin Lv, **Yuxian Gu**, Xu Han, Lei Hou, Juanzi Li, Zhiyuan Liu. Adapting Meta Knowledge Graph Information for Multi-Hop Reasoning over Few-Shot Relations. **EMNLP 2019** (CCF-B Short Paper). [[pdf]](https://aclanthology.org/D19-1334.pdf) [[code]](https://github.com/THU-KEG/MetaKGR)

**Journal Papers**

+ Zhengyan Zhang\*, **Yuxian Gu\***, Xu Han\*, Shengqi Chen\*, Chaojun Xiao\*, Zhenbo Sun, Yuan Yao, Fanchao Qi, Jian Guan, Pei Ke, Yanzheng Cai, Guoyang Zeng, Zhixing Tan, Zhiyuan Liu, Minlie Huang, Wentao Han, Yang Liu, Xiaoyan Zhu, Maosong Sun. CPM-2: Large-Scale Cost-Effective Pre-Trained Language Models. 2022. **AI Open**. [[pdf]](https://www.sciencedirect.com/science/article/pii/S2666651021000310/pdfft?md5=46efc536c128aefd0ff69139f8627ddb&pid=1-s2.0-S2666651021000310-main.pdf) [[pre-train code]](https://github.com/TsinghuaAI/CPM-2-Pretrain) [[fine-tune code]](https://github.com/TsinghuaAI/CPM-1-Finetune)

+ Xu Han\*, Zhengyan Zhang\*, Ning Ding\*, **Yuxian Gu\***, Xiao Liu\*, Yuqi Huo\*, Jiezhong Qiu, Yuan Yao, Ao Zhang, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu, Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen, Jinhui Yuan, Wayne Xin Zhao, Jun Zhu. Pre-Trained Models: Past, Present and Future. 2022. **AI Open**. [[pdf]](https://www.sciencedirect.com/science/article/pii/S2666651021000231/pdfft?md5=e87250d675adde41b6836aed4df648b4&pid=1-s2.0-S2666651021000231-main.pdf)

+ Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, **Yuxian Gu**, Deming Ye, Yujia Qin, Yusheng Su, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun. CPM: A Large-Scale Generative Chinese Pre-Trained Language Model. 2021. **AI Open**. [[pdf]](https://www.sciencedirect.com/science/article/pii/S266665102100019X/pdfft?md5=c9c82038f6f237b8708270ed0fbbf80b&pid=1-s2.0-S266665102100019X-main.pdf) [[pre-train code]](https://github.com/TsinghuaAI/CPM-1-Pretrain) [[fine-tune code]](https://github.com/TsinghuaAI/CPM-1-Finetune) [[inference code]](https://github.com/TsinghuaAI/CPM-1-Generate)

**Preprints**

+ **Yuxian Gu\***, Jiaxin Wen\*, Hao Sun\*, Yi Song, Pei Ke, Chujie Zheng, Zheng Zhang, Jianzhu Yao, Xiaoyan Zhu, Jie Tang, Minlie Huang. EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training. arXiv preprint 2022. [[pdf]](https://arxiv.org/pdf/2203.09313.pdf) [[code]](https://github.com/thu-coai/EVA/)

+ Yi Song\*, **Yuxian Gu\***, Minlie Huang. Many-Class Text Classification with Matching. arXiv preprint 2022. [[pdf]](https://arxiv.org/pdf/2205.11409.pdf)

+ Hao Zhou, Pei Ke, Zheng Zhang, **Yuxian Gu**, Yinhe Zheng, Chujie Zheng, Yida Wang, Chen Henry Wu, Hao Sun, Xiaocong Yang, Bosi Wen, Xiaoyan Zhu, Minlie Huang, Jie Tang. EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Training. arXiv preprint 2021. [[pdf]](https://arxiv.org/pdf/2108.01547.pdf) [[code]](https://github.com/thu-coai/EVA/)

Teaching
======
I was a TA for the following undergraduate courses:

+ Artificial Neural Network (2020 Fall, 2021 Fall, 2022 Fall)
+ Object-Oriented Programming (2021 Spring, 2022 Spring)

Selected Honors and Awards
======

+ Excellent Graduate, Tsinghua University, 2021
+ Outstanding Graduate, Dept. CST, Tsinghua University, 2021
+ Outstanding Undergraduate Dissertation, Tsinghua University, 2021
+ Overall Scholarship, Dept. CST, Tsinghua University, 2020
+ Science and Technology Innovation Excellence Scholarship, Dept. CST, Tsinghua University, 2019
+ Silver Prize, Asia Student Supercomputer Challenge, Asia Supercomputer Community, 2019
+ Overall Scholarship, Dept. CST, Tsinghua University, 2018

<!-- I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful. -->
